{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PCA algorithm to reduce the dimension of your data"
      ],
      "metadata": {
        "id": "Vaqv2E7GtV1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Principal component analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set."
      ],
      "metadata": {
        "id": "3l2jb6NtuxDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H8-u_KigtSMw"
      },
      "outputs": [],
      "source": [
        "def compute_pca(X, n_components=2):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        X: of dimension (m,n) where each row corresponds to a word vector\n",
        "        n_components: Number of components you want to keep.\n",
        "    Output:\n",
        "        X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
        "    pass in: data as 2D NumPy array\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # mean center the data\n",
        "    X_demeaned = X - np.mean(X,axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix, UPLO='L')\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "    \n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = idx_sorted[::-1]\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    eigen_vecs_sorted = eigen_vecs[:, idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:, 0:n_components]\n",
        "\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.T, X_demeaned.T).T\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X_reduced\n"
      ]
    }
  ]
}